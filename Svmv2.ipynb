{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\MSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\MSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords , wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Download necessary NLTK datasets\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            question        label\n",
      "0  How did serfdom develop in and then leave Russ...  DESC:manner\n",
      "1   What films featured the character Popeye Doyle ?  ENTY:cremat\n",
      "2  How can I find a list of celebrities ' real na...  DESC:manner\n",
      "3  What fowl grabs the spotlight after the Chines...  ENTY:animal\n",
      "4                    What is the full form of .com ?     ABBR:exp\n"
     ]
    }
   ],
   "source": [
    "def load_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            # Split label and question\n",
    "            label, question = line.strip().split(' ', 1)\n",
    "            data.append({\"question\": question, \"label\": label})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "train_set = load_data(\".\\data\\\\train_set5.txt\")\n",
    "test_set = load_data(\".\\data\\\\test_set.txt\")\n",
    "\n",
    "print(train_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    words = word_tokenize(text)\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "train_set['processed_question'] = train_set['question'].apply(preprocess_text)\n",
    "test_set['processed_question'] = test_set['question'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               serfdom develop leave russia\n",
       "1       film featured character popeye doyle\n",
       "2              find list celebrity real name\n",
       "3    fowl grab spotlight chinese year monkey\n",
       "4                              full form com\n",
       "Name: processed_question, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['processed_question'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         label category specific_type\n",
      "0  DESC:manner     DESC        manner\n",
      "1  ENTY:cremat     ENTY        cremat\n",
      "2  DESC:manner     DESC        manner\n",
      "3  ENTY:animal     ENTY        animal\n",
      "4     ABBR:exp     ABBR           exp\n"
     ]
    }
   ],
   "source": [
    "train_set[['category', 'specific_type']] = train_set['label'].str.split(':', expand=True)\n",
    "test_set[['category', 'specific_type']] = test_set['label'].str.split(':', expand=True)\n",
    "\n",
    "print(train_set[['label', 'category', 'specific_type']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  category specific_type  category_encoded  specific_type_encoded\n",
      "0     DESC        manner                 1                     23\n",
      "1     ENTY        cremat                 2                      8\n",
      "2     DESC        manner                 1                     23\n",
      "3     ENTY        animal                 2                      1\n",
      "4     ABBR           exp                 0                     16\n"
     ]
    }
   ],
   "source": [
    "category_encoder = LabelEncoder()\n",
    "specific_type_encoder = LabelEncoder()\n",
    "\n",
    "train_set['category_encoded'] = category_encoder.fit_transform(train_set['category'])\n",
    "train_set['specific_type_encoded'] = specific_type_encoder.fit_transform(train_set['specific_type'])\n",
    "\n",
    "test_set['category_encoded'] = category_encoder.transform(test_set['category'])\n",
    "test_set['specific_type_encoded'] = specific_type_encoder.transform(test_set['specific_type'])\n",
    "\n",
    "print(train_set[['category', 'specific_type', 'category_encoded', 'specific_type_encoded']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  combined_label  combined_label_encoded\n",
      "0    DESC_manner                       4\n",
      "1    ENTY_cremat                       9\n",
      "2    DESC_manner                       4\n",
      "3    ENTY_animal                       6\n",
      "4       ABBR_exp                       1\n"
     ]
    }
   ],
   "source": [
    "train_set['combined_label'] = train_set['category'] + \"_\" + train_set['specific_type']\n",
    "test_set['combined_label'] = test_set['category'] + \"_\" + test_set['specific_type']\n",
    "\n",
    "combined_label_encoder = LabelEncoder()\n",
    "train_set['combined_label_encoded'] = combined_label_encoder.fit_transform(train_set['combined_label'])\n",
    "test_set['combined_label_encoded'] = combined_label_encoder.transform(test_set['combined_label'])\n",
    "\n",
    "print(train_set[['combined_label', 'combined_label_encoded']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>processed_question</th>\n",
       "      <th>category</th>\n",
       "      <th>specific_type</th>\n",
       "      <th>category_encoded</th>\n",
       "      <th>specific_type_encoded</th>\n",
       "      <th>combined_label</th>\n",
       "      <th>combined_label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How did serfdom develop in and then leave Russ...</td>\n",
       "      <td>DESC:manner</td>\n",
       "      <td>serfdom develop leave russia</td>\n",
       "      <td>DESC</td>\n",
       "      <td>manner</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>DESC_manner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What films featured the character Popeye Doyle ?</td>\n",
       "      <td>ENTY:cremat</td>\n",
       "      <td>film featured character popeye doyle</td>\n",
       "      <td>ENTY</td>\n",
       "      <td>cremat</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>ENTY_cremat</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I find a list of celebrities ' real na...</td>\n",
       "      <td>DESC:manner</td>\n",
       "      <td>find list celebrity real name</td>\n",
       "      <td>DESC</td>\n",
       "      <td>manner</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>DESC_manner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What fowl grabs the spotlight after the Chines...</td>\n",
       "      <td>ENTY:animal</td>\n",
       "      <td>fowl grab spotlight chinese year monkey</td>\n",
       "      <td>ENTY</td>\n",
       "      <td>animal</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>ENTY_animal</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the full form of .com ?</td>\n",
       "      <td>ABBR:exp</td>\n",
       "      <td>full form com</td>\n",
       "      <td>ABBR</td>\n",
       "      <td>exp</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>ABBR_exp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question        label  \\\n",
       "0  How did serfdom develop in and then leave Russ...  DESC:manner   \n",
       "1   What films featured the character Popeye Doyle ?  ENTY:cremat   \n",
       "2  How can I find a list of celebrities ' real na...  DESC:manner   \n",
       "3  What fowl grabs the spotlight after the Chines...  ENTY:animal   \n",
       "4                    What is the full form of .com ?     ABBR:exp   \n",
       "\n",
       "                        processed_question category specific_type  \\\n",
       "0             serfdom develop leave russia     DESC        manner   \n",
       "1     film featured character popeye doyle     ENTY        cremat   \n",
       "2            find list celebrity real name     DESC        manner   \n",
       "3  fowl grab spotlight chinese year monkey     ENTY        animal   \n",
       "4                            full form com     ABBR           exp   \n",
       "\n",
       "   category_encoded  specific_type_encoded combined_label  \\\n",
       "0                 1                     23    DESC_manner   \n",
       "1                 2                      8    ENTY_cremat   \n",
       "2                 1                     23    DESC_manner   \n",
       "3                 2                      1    ENTY_animal   \n",
       "4                 0                     16       ABBR_exp   \n",
       "\n",
       "   combined_label_encoded  \n",
       "0                       4  \n",
       "1                       9  \n",
       "2                       4  \n",
       "3                       6  \n",
       "4                       1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "ENTY    1250\n",
      "HUM     1223\n",
      "DESC    1162\n",
      "NUM      896\n",
      "LOC      835\n",
      "ABBR      86\n",
      "Name: count, dtype: int64\n",
      "specific_type\n",
      "ind          962\n",
      "other        733\n",
      "def          421\n",
      "count        363\n",
      "desc         321\n",
      "manner       276\n",
      "date         218\n",
      "cremat       207\n",
      "reason       191\n",
      "gr           189\n",
      "country      155\n",
      "city         129\n",
      "animal       112\n",
      "food         103\n",
      "dismed       103\n",
      "termeq        93\n",
      "period        75\n",
      "money         71\n",
      "exp           70\n",
      "state         66\n",
      "sport         62\n",
      "event         56\n",
      "product       42\n",
      "substance     41\n",
      "color         40\n",
      "techmeth      38\n",
      "dist          34\n",
      "veh           27\n",
      "perc          27\n",
      "word          26\n",
      "title         25\n",
      "mount         21\n",
      "body          16\n",
      "abb           16\n",
      "lang          16\n",
      "plant         13\n",
      "volsize       13\n",
      "weight        11\n",
      "symbol        11\n",
      "instru        10\n",
      "letter         9\n",
      "code           9\n",
      "speed          9\n",
      "temp           8\n",
      "ord            6\n",
      "religion       4\n",
      "currency       4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_set['category'].value_counts())\n",
    "print(train_set['specific_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW Train Feature Shape: (5452, 8411)\n",
      "BOW Test Feature Shape: (500, 8411)\n",
      "WordNet Synsets Train Feature Shape: (5452, 7074)\n",
      "WordNet Synsets Test Feature Shape: (500, 7074)\n"
     ]
    }
   ],
   "source": [
    "# 2. Feature Extraction\n",
    "# Bag-of-Words representation\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_bow = vectorizer.fit_transform(train_set.question)\n",
    "X_test_bow = vectorizer.transform(test_set.question)\n",
    "\n",
    "# Test Bag-of-Words\n",
    "print(\"BOW Train Feature Shape:\", X_train_bow.shape)\n",
    "print(\"BOW Test Feature Shape:\", X_test_bow.shape)\n",
    "\n",
    "# WordNet Synsets as Features\n",
    "def wordnet_features(questions):\n",
    "    features = []\n",
    "    for question in questions:\n",
    "        tokens = nltk.word_tokenize(question)\n",
    "        synset_features = []\n",
    "        for token in tokens:\n",
    "            synsets = wordnet.synsets(token)\n",
    "            # Use the first lemma name of the first synset if available, else use the token\n",
    "            synset_features.append(synsets[0].lemma_names()[0] if synsets else token)\n",
    "        features.append(\" \".join(synset_features))\n",
    "    return features\n",
    "\n",
    "# Test WordNet Synsets\n",
    "X_train_synsets = vectorizer.fit_transform(wordnet_features(train_set.question))\n",
    "X_test_synsets = vectorizer.transform(wordnet_features(test_set.question))\n",
    "print(\"WordNet Synsets Train Feature Shape:\", X_train_synsets.shape)\n",
    "print(\"WordNet Synsets Test Feature Shape:\", X_test_synsets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Train Feature Shape: (5452, 15485)\n",
      "Combined Test Feature Shape: (500, 15485)\n"
     ]
    }
   ],
   "source": [
    "# Combine Features (Bag-of-Words + Synsets)\n",
    "X_train_combined = np.hstack([X_train_bow.toarray(), X_train_synsets.toarray()])\n",
    "X_test_combined = np.hstack([X_test_bow.toarray(), X_test_synsets.toarray()])\n",
    "\n",
    "# Test combined features\n",
    "print(\"Combined Train Feature Shape:\", X_train_combined.shape)\n",
    "print(\"Combined Test Feature Shape:\", X_test_combined.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;, probability=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear', probability=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modeling with SVM\n",
    "y_train = train_set['combined_label_encoded']\n",
    "y_test = test_set['combined_label_encoded']\n",
    "# Train the model using the combined labels\n",
    "svm_model = SVC(kernel='linear',random_state=42)\n",
    "svm_model.fit(X_train_combined,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.86      0.75      0.80         8\n",
      "           2       0.77      1.00      0.87       123\n",
      "           3       0.56      0.71      0.63         7\n",
      "           4       0.67      1.00      0.80         2\n",
      "           5       1.00      1.00      1.00         6\n",
      "           6       1.00      0.69      0.81        16\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       1.00      1.00      1.00        10\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       1.00      0.50      0.67         6\n",
      "          11       1.00      0.50      0.67         2\n",
      "          12       0.00      0.00      0.00         2\n",
      "          13       1.00      0.25      0.40         4\n",
      "          14       1.00      1.00      1.00         1\n",
      "          15       1.00      1.00      1.00         2\n",
      "          17       0.33      0.42      0.37        12\n",
      "          18       1.00      0.20      0.33         5\n",
      "          19       0.00      0.00      0.00         4\n",
      "          21       1.00      1.00      1.00         1\n",
      "          22       0.83      0.33      0.48        15\n",
      "          24       1.00      1.00      1.00         1\n",
      "          25       0.54      1.00      0.70         7\n",
      "          26       0.00      0.00      0.00         4\n",
      "          28       0.75      1.00      0.86         3\n",
      "          29       0.60      0.50      0.55         6\n",
      "          30       0.88      0.93      0.90        55\n",
      "          31       0.00      0.00      0.00         1\n",
      "          32       1.00      0.78      0.88        18\n",
      "          33       1.00      1.00      1.00         3\n",
      "          34       1.00      0.67      0.80         3\n",
      "          35       0.84      0.84      0.84        50\n",
      "          36       0.54      1.00      0.70         7\n",
      "          38       0.75      1.00      0.86         9\n",
      "          39       1.00      0.98      0.99        47\n",
      "          40       1.00      0.56      0.72        16\n",
      "          41       1.00      0.33      0.50         3\n",
      "          43       1.00      0.42      0.59        12\n",
      "          44       0.50      0.33      0.40         3\n",
      "          45       0.73      1.00      0.84         8\n",
      "          46       1.00      0.50      0.67         6\n",
      "          47       1.00      0.80      0.89         5\n",
      "          49       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.81       500\n",
      "   macro avg       0.75      0.65      0.66       500\n",
      "weighted avg       0.83      0.81      0.80       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score,classification_report\n",
    "# Predictions\n",
    "y_pred = svm_model.predict(X_test_combined)\n",
    "# Generate the classification report\n",
    "print(\"Test Set Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5452\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "print(len(y_pred))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5452, 100)\n",
      "(500, 100)\n",
      "(5452,)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Training Word2Vec model\n",
    "tokenized_text = train_set['processed_question'].tolist()\n",
    "word2vec_model = Word2Vec(sentences=tokenized_text, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to get the average Word2Vec embedding for a question\n",
    "def get_word2vec_embedding(sentence, model):\n",
    "    embeddings = [model.wv[word] for word in sentence if word in model.wv]\n",
    "    return np.mean(embeddings, axis=0) if embeddings else np.zeros(model.vector_size)\n",
    "\n",
    "# Apply the function to both train and test sets\n",
    "train_set['word2vec'] = train_set['processed_question'].apply(lambda x: get_word2vec_embedding(x, word2vec_model))\n",
    "test_set['word2vec'] = test_set['processed_question'].apply(lambda x: get_word2vec_embedding(x, word2vec_model))\n",
    "\n",
    "# Prepare the features and target variable\n",
    "X_train = np.vstack(train_set['word2vec'])\n",
    "X_test = np.vstack(test_set['word2vec'])\n",
    "y_train = train_set['combined_label_encoded']\n",
    "y_test = test_set['combined_label_encoded']\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear', random_state=42)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using the combined labels\n",
    "svm_model = SVC(kernel='linear',random_state=42)\n",
    "svm_model.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.77      0.66      0.71       123\n",
      "           3       0.00      0.00      0.00         7\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         6\n",
      "           6       0.00      0.00      0.00        16\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00        10\n",
      "          10       0.00      0.00      0.00         6\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       0.00      0.00      0.00         2\n",
      "          13       0.00      0.00      0.00         4\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.00      0.00      0.00         2\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.00      0.00      0.00         5\n",
      "          19       0.00      0.00      0.00         4\n",
      "          21       0.00      0.00      0.00         1\n",
      "          22       0.00      0.00      0.00        15\n",
      "          24       0.00      0.00      0.00         1\n",
      "          25       0.00      0.00      0.00         7\n",
      "          26       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00         3\n",
      "          29       0.00      0.00      0.00         6\n",
      "          30       0.13      0.93      0.23        55\n",
      "          31       0.00      0.00      0.00         1\n",
      "          32       0.00      0.00      0.00        18\n",
      "          33       0.00      0.00      0.00         3\n",
      "          34       0.00      0.00      0.00         3\n",
      "          35       0.00      0.00      0.00        50\n",
      "          36       0.00      0.00      0.00         7\n",
      "          38       0.00      0.00      0.00         9\n",
      "          39       0.00      0.00      0.00        47\n",
      "          40       0.00      0.00      0.00        16\n",
      "          41       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00        12\n",
      "          44       0.00      0.00      0.00         3\n",
      "          45       0.00      0.00      0.00         8\n",
      "          46       0.00      0.00      0.00         6\n",
      "          47       0.00      0.00      0.00         5\n",
      "          49       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.26       500\n",
      "   macro avg       0.02      0.04      0.02       500\n",
      "weighted avg       0.20      0.26      0.20       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "y_pred = svm_model.predict(X_test)\n",
    "# Generate the classification report\n",
    "print(\"Test Set Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained Word2Vec model...\n",
      "Word2Vec model loaded!\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# Load pretrained Word2Vec model\n",
    "print(\"Loading pretrained Word2Vec model...\")\n",
    "w2v_model = KeyedVectors.load_word2vec_format(r\"C:\\Users\\MSI\\Downloads\\GoogleNews-vectors-negative300.bin\\GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "print(\"Word2Vec model loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute Word2Vec embeddings for a text\n",
    "def compute_w2v_embedding(words, model, vector_size=300):\n",
    "    embeddings = [model[word] for word in words if word in model]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)  # Average embedding\n",
    "    else:\n",
    "        return np.zeros(vector_size)  # Return zero vector if no words match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Word2Vec embeddings...\n",
      "Embeddings generated!\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for train and test sets\n",
    "print(\"Generating Word2Vec embeddings...\")\n",
    "train_embeddings = np.array([compute_w2v_embedding(words, w2v_model) for words in train_set['processed_question']])\n",
    "test_embeddings = np.array([compute_w2v_embedding(words, w2v_model) for words in test_set['processed_question']])\n",
    "print(\"Embeddings generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, probability=True, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;, probability=True, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear', probability=True, random_state=42)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train SVM classifier\n",
    "print(\"Training SVM model...\")\n",
    "svm_model = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm_model.fit(train_embeddings, train_set['combined_label_encoded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Test Accuracy: 15.00%\n",
      "                                   question     label predicted_label\n",
      "0      How far is it from Denver to Aspen ?  NUM:dist         HUM_ind\n",
      "1  What county is Modesto , California in ?  LOC:city         HUM_ind\n",
      "2                         Who was Galileo ?  HUM:desc         HUM_ind\n",
      "3                         What is an atom ?  DESC:def        DESC_def\n",
      "4          When did Hawaii become a state ?  NUM:date         HUM_ind\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "print(\"Making predictions...\")\n",
    "test_predictions = svm_model.predict(test_embeddings)\n",
    "\n",
    "# Decode predictions\n",
    "test_set['predicted_label'] = combined_label_encoder.inverse_transform(test_predictions)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = np.mean(test_predictions == test_set['combined_label_encoded'])\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display predictions\n",
    "print(test_set[['question', 'label', 'predicted_label']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
